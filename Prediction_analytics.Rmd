---
title: "Predictive_Analytics"
author: "H"
date: "12/15/2021"
output: html_document
---

```{r}
df <- read.csv("Marketing_Analysis_IBM.csv")
```
```{r}
df
```
### Encode response data yes 1 no 0
```{r}
df$Engaged <- ifelse(df$Response == "Yes", 1, 0)
```
```{r}
df
```

```{r}
mean(df$Engaged)
```
## Categorical Variable encoding 
```{r}
categoricalVars =c('Sales.Channel','Vehicle.Size', "Vehicle.Class", "Policy", "Policy.Type","EmploymentStatus", "Marital.Status", "Education",  "Coverage", "Gender" )
```

```{r}
encodeDF <- model.matrix(~. -1, df[categoricalVars])
```

```{r}
encodeDF
```
### Continuous Feature 
```{r}
continuousFeatures <- c("Customer.Lifetime.Value", "Income", "Monthly.Premium.Auto","Months.Since.Last.Claim", "Months.Since.Policy.Inception", "Number.of.Open.Complaints", "Number.of.Policies", "Total.Claim.Amount"  )
```
```{r}
encodeDF <- cbind(encodeDF, df[continuousFeatures])
```
##building predictive models 

```{r}
library(caTools)
```
### CaTool is for split the sample set, one for training the model, another one for testing and evaluating the trained model. 
```{r}
sample <-sample.split(df$Customer,SplitRatio = .7)
trainX <- as.matrix(subset(encodeDF, sample == TRUE))
trainY <- as.double(as.matrix(subset(df$Engaged, sample == TRUE)))
```

```{r}
testX <- as.matrix(subset(encodeDF, sample == FALSE))
testY <- as.double(as.matrix(subset(df$Engaged, sample == FALSE)))
```
### using sample.split function take 70% of sample from Customer, remains 30% of sample set as a test set.  And result variable, sample has an array of Boolean value TRUE, FALSE - 70% of arrays are TRUE, 30% array is FALSE
#### Correspond TRUE as Train set , Correspond FALSE as Test set. 


## Random Forest model
```{r}
library(randomForest)
```

```{r}
rfModel <- randomForest(x= trainX, y =factor(trainY), ntree= 200, maxnodes= 24)
```
```{r}
rfModel
```
```{r}
getTree(rfModel, 1)
```
```{r}
predict(rfModel, trainX, predict.all =TRUE)
```
### we can understand the importance or the impact of each feature on the final predictions
```{r}
importance(rfModel)
```
### Evaluating a classification model
```{r}
inSamplePreds <- as.double(predict(rfModel, trainX)) -1
outSamplePreds <- as.double(predict(rfModel, testX)) -1
```
### Accuracy, precision, Recall
```{r}
accuracy <- mean(testY == outSamplePreds)
precision <- sum(outSamplePreds & testY)/ sum(outSamplePreds)
recall <- sum(outSamplePreds & testY) / sum(testY)
```
```{r}
inSampleAccuracy <- mean(trainY == inSamplePreds)
OutSampleAaccuracy <- mean(testY == outSamplePreds)

```
```{r}
InSamplePrecision <- sum(inSamplePreds & trainY)/ sum(inSamplePreds)
OutSamplePrecision <- sum(outSamplePreds & testY)/ sum(outSamplePreds)

```
```{r}
InSamplerecall <- sum(inSamplePreds & trainY) / sum(trainY)
OutSamrecall <- sum(outSamplePreds & testY) / sum(testY)

```



```{r}
print(sprintf('In-Sample Accuracy :%0.4f', inSampleAccuracy))
print(sprintf('Out-Sample Accuracy :%0.4f', OutSampleAaccuracy))

```
```{r}
print(sprintf('In-Sample Precision :%0.4f', InSamplePrecision))
print(sprintf('Out-Sample Precision :%0.4f', OutSamplePrecision))
```
```{r}
print(sprintf('In-Sample Recall :%0.4f', InSamplerecall))
print(sprintf('Out-Sample recall :%0.4f', OutSamrecall))
```
```{r}
library(ROCR)
```
```{r}
inSamplePredProbs <- as.double(predict(rfModel, trainX, type = 'prob')[, 2])
OutSamplePredProbs <- as.double(predict(rfModel, testX, type = 'prob')[, 2])

```
```{r}
pred <- prediction(OutSamplePredProbs, testY)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
auc <- performance(pred, measure = "auc")@y.values[[1]]
```
```{r}
plot (perf , main= sprintf("Random Forest Model ROC Curve(AUC :%0.2f", auc), col ="darkorange", lwd =2 )+
  grid() + abline(a =0 , b= 1 , col ="gray", lty =3 ,lwd =2)
```

